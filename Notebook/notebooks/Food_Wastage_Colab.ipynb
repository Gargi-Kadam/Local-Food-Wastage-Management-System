{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83c\udf72 Local Food Wastage Analytics \u2014 EDA, Hypothesis Tests & ML (Colab)\n", "**Datasets:** `providers_data.csv`, `receivers_data.csv`, `food_listings_data.csv`, `claims_data.csv`  \n", "**Goal:** Do end\u2011to\u2011end EDA, clean & prepare data, test 3 hypotheses, and build **classification models** to predict claim success \u2014 with clear, reproducible charts.\n", "\n", "> Tip: Upload all 4 CSVs into Colab's `/content` then run the notebook top\u2011to\u2011bottom."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 0. Setup (Install & Imports)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Detect Colab and install extras\n", "try:\n", "    import google.colab  # type: ignore\n", "    IN_COLAB = True\n", "except Exception:\n", "    IN_COLAB = False\n", "\n", "if IN_COLAB:\n", "    !pip -q install xgboost shap imbalanced-learn\n", "\n", "import os, re, warnings, itertools\n", "warnings.filterwarnings('ignore')\n", "\n", "import numpy as np\n", "import pandas as pd\n", "from datetime import datetime, timedelta\n", "import matplotlib.pyplot as plt  # (no seaborn per project constraints)\n", "\n", "from scipy import stats\n", "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n", "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n", "from sklearn.compose import ColumnTransformer\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n", "                             confusion_matrix, RocCurveDisplay, ConfusionMatrixDisplay, classification_report)\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import RandomForestClassifier\n", "from imblearn.over_sampling import SMOTE\n", "\n", "# Optional libs\n", "try:\n", "    import shap\n", "    SHAP_AVAILABLE = True\n", "except Exception:\n", "    SHAP_AVAILABLE = False\n", "\n", "try:\n", "    from xgboost import XGBClassifier\n", "    XGB_AVAILABLE = True\n", "except Exception:\n", "    XGB_AVAILABLE = False\n", "\n", "RANDOM_STATE = 42\n", "np.random.seed(RANDOM_STATE)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 1. Load the 4 datasets"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# ===== Option A: Upload manually =====\n", "if IN_COLAB:\n", "    from google.colab import files\n", "    print(\"\ud83d\udc49 Upload the 4 CSVs: providers_data.csv, receivers_data.csv, food_listings_data.csv, claims_data.csv\")\n", "    _ = files.upload()\n", "\n", "# ===== Option B: Use path if files already present =====\n", "DATA_DIR = \".\"  # change to \"/content\" if needed\n", "\n", "prov_path  = os.path.join(DATA_DIR, \"providers_data.csv\")\n", "recv_path  = os.path.join(DATA_DIR, \"receivers_data.csv\")\n", "food_path  = os.path.join(DATA_DIR, \"food_listings_data.csv\")\n", "claim_path = os.path.join(DATA_DIR, \"claims_data.csv\")\n", "\n", "missing = [p for p in [prov_path, recv_path, food_path, claim_path] if not os.path.exists(p)]\n", "if missing:\n", "    print(\"\u26a0\ufe0f Missing files:\", missing, \"\\nUpload them or fix DATA_DIR before proceeding.\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 1.1 Robust CSV Reader + Column Normalization"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n", "    out = df.copy()\n", "    out.columns = [re.sub(r'[^0-9a-zA-Z_]', '', c.strip().lower().replace(' ', '_')) for c in out.columns]\n", "    return out\n", "\n", "# Expected canonical columns after normalization:\n", "# providers: provider_id, name, type, city, contact, address?, provider_type?\n", "# receivers: receiver_id, name, type, city, contact, address?, receiver_type?\n", "# food_listings: food_id, food_name, quantity, expiry_date, provider_id, provider_type?, location, food_type, meal_type\n", "# claims: claim_id, food_id, receiver_id, status, timestamp\n", "\n", "def read_providers_csv(path):\n", "    df = normalize_columns(pd.read_csv(path))\n", "    df.rename(columns={'providerid':'provider_id', 'providerid_':'provider_id'}, inplace=True)\n", "    required = ['provider_id','name','type','city','contact']\n", "    for col in required:\n", "        if col not in df.columns:\n", "            raise ValueError(f\"[providers] missing column: {col}\")\n", "    if 'address' not in df.columns: df['address'] = np.nan\n", "    if 'provider_type' not in df.columns: df['provider_type'] = df['type']\n", "    return df[['provider_id','name','type','city','contact','address','provider_type']]\n", "\n", "def read_receivers_csv(path):\n", "    df = normalize_columns(pd.read_csv(path))\n", "    df.rename(columns={'receiverid':'receiver_id', 'receiverid_':'receiver_id'}, inplace=True)\n", "    required = ['receiver_id','name','type','city','contact']\n", "    for col in required:\n", "        if col not in df.columns:\n", "            raise ValueError(f\"[receivers] missing column: {col}\")\n", "    if 'address' not in df.columns: df['address'] = np.nan\n", "    if 'receiver_type' not in df.columns: df['receiver_type'] = df['type']\n", "    return df[['receiver_id','name','type','city','contact','address','receiver_type']]\n", "\n", "def read_food_listings_csv(path):\n", "    df = normalize_columns(pd.read_csv(path))\n", "    df.rename(columns={'foodid':'food_id', 'foodid_':'food_id', 'providerid':'provider_id'}, inplace=True)\n", "    required = ['food_id','food_name','quantity','expiry_date','provider_id','location','food_type','meal_type']\n", "    for col in required:\n", "        if col not in df.columns:\n", "            raise ValueError(f\"[food_listings] missing column: {col}\")\n", "    if 'provider_type' not in df.columns: df['provider_type'] = np.nan\n", "    df['expiry_date'] = pd.to_datetime(df['expiry_date'], errors='coerce', infer_datetime_format=True)\n", "    return df[['food_id','food_name','quantity','expiry_date','provider_id','provider_type','location','food_type','meal_type']]\n", "\n", "def read_claims_csv(path):\n", "    df = normalize_columns(pd.read_csv(path))\n", "    df.rename(columns={'claimid':'claim_id','foodid':'food_id','receiverid':'receiver_id'}, inplace=True)\n", "    required = ['claim_id','food_id','receiver_id','status','timestamp']\n", "    for col in required:\n", "        if col not in df.columns:\n", "            raise ValueError(f\"[claims] missing column: {col}\")\n", "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce', infer_datetime_format=True)\n", "    return df[['claim_id','food_id','receiver_id','status','timestamp']]\n", "\n", "providers = read_providers_csv(prov_path)\n", "receivers  = read_receivers_csv(recv_path)\n", "food       = read_food_listings_csv(food_path)\n", "claims     = read_claims_csv(claim_path)\n", "\n", "print(\"Shapes -> providers:\", providers.shape, \"| receivers:\", receivers.shape, \"| food:\", food.shape, \"| claims:\", claims.shape)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 2. Know Your Data \u2014 First Look"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["display(providers.head())\n", "display(receivers.head())\n", "display(food.head())\n", "display(claims.head())\n", "\n", "print(\"\\nInfo: providers\"); print(providers.info())\n", "print(\"\\nInfo: receivers\"); print(receivers.info())\n", "print(\"\\nInfo: food\"); print(food.info())\n", "print(\"\\nInfo: claims\"); print(claims.info())\n", "\n", "print(\"\\nRows & Cols:\",\n", "      {\"providers\": providers.shape,\n", "       \"receivers\": receivers.shape,\n", "       \"food\": food.shape,\n", "       \"claims\": claims.shape})\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 2.1 Duplicates & Missing Values"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Duplicates\n", "print(\"Duplicate rows -> providers:\", providers.duplicated().sum())\n", "print(\"Duplicate rows -> receivers:\", receivers.duplicated().sum())\n", "print(\"Duplicate rows -> food:\", food.duplicated().sum())\n", "print(\"Duplicate rows -> claims:\", claims.duplicated().sum())\n", "\n", "# Missing summaries\n", "def na_summary(df, name):\n", "    s = df.isna().sum()\n", "    pct = (s/len(df))*100\n", "    out = pd.DataFrame({\"column\": s.index, \"na_count\": s.values, \"na_pct\": pct.values})\n", "    out = out[out.na_count>0].sort_values(\"na_pct\", ascending=False)\n", "    print(f\"\\n{name} \u2014 Missing summary:\")\n", "    display(out if len(out) else pd.DataFrame({\"note\":[f\"No missing in {name}\"]}))\n", "\n", "for n, d in [(\"providers\", providers), (\"receivers\", receivers), (\"food\", food), (\"claims\", claims)]:\n", "    na_summary(d, n)\n", "\n", "# Simple missing \"matrix\"\n", "def plot_missing_matrix(df, title):\n", "    plt.figure()\n", "    plt.imshow(df.isna(), aspect='auto', interpolation='nearest')\n", "    plt.title(title)\n", "    plt.xlabel(\"Columns\")\n", "    plt.ylabel(\"Rows\")\n", "    plt.xticks(range(len(df.columns)), df.columns, rotation=90, fontsize=8)\n", "    plt.tight_layout()\n", "    plt.show()\n", "\n", "plot_missing_matrix(providers, \"Missing Matrix \u2014 Providers\")\n", "plot_missing_matrix(receivers, \"Missing Matrix \u2014 Receivers\")\n", "plot_missing_matrix(food, \"Missing Matrix \u2014 Food\")\n", "plot_missing_matrix(claims, \"Missing Matrix \u2014 Claims\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 3. Build Analysis Tables (Joins)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["cf   = claims.merge(food, on='food_id', how='left', suffixes=('_claim','_food'))\n", "cfp  = cf.merge(providers, on='provider_id', how='left', suffixes=('','_prov'))\n", "full = cfp.merge(receivers, on='receiver_id', how='left', suffixes=('','_recv'))\n", "\n", "print(\"Merged table shape:\", full.shape)\n", "display(full.head(3))\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 4. EDA Visualizations (matplotlib-only)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["def bar_count(series, title, xlabel=\"Category\", ylabel=\"Count\"):\n", "    counts = series.value_counts(dropna=False)\n", "    plt.figure()\n", "    counts.plot(kind='bar')\n", "    plt.title(title)\n", "    plt.xlabel(xlabel)\n", "    plt.ylabel(ylabel)\n", "    plt.tight_layout()\n", "    plt.show()\n", "\n", "# Counts\n", "bar_count(food['food_type'], \"Food Type Distribution\")\n", "bar_count(food['meal_type'], \"Meal Type Distribution\")\n", "bar_count(food['location'], \"Listings by Location\")\n", "bar_count(providers['provider_type'].fillna(\"Unknown\"), \"Provider Type Distribution\")\n", "bar_count(providers['city'], \"Providers by City\")\n", "\n", "# Claims by status\n", "bar_count(claims['status'].str.lower(), \"Claims by Status\")\n", "\n", "# Quantity hist & box\n", "plt.figure()\n", "plt.hist(food['quantity'].dropna(), bins=30)\n", "plt.title(\"Quantity Distribution\")\n", "plt.xlabel(\"Quantity\")\n", "plt.ylabel(\"Frequency\")\n", "plt.tight_layout()\n", "plt.show()\n", "\n", "plt.figure()\n", "plt.boxplot(food['quantity'].dropna(), vert=True)\n", "plt.title(\"Quantity Boxplot (Outliers visible)\")\n", "plt.ylabel(\"Quantity\")\n", "plt.tight_layout()\n", "plt.show()\n", "\n", "# Simple numeric correlation\n", "num_df = full.select_dtypes(include=[np.number]).copy()\n", "if num_df.shape[1] > 1:\n", "    corr = num_df.corr(numeric_only=True)\n", "    plt.figure()\n", "    im = plt.imshow(corr, interpolation='nearest')\n", "    plt.title(\"Correlation Heatmap (numeric)\")\n", "    plt.colorbar(im, fraction=0.046, pad=0.04)\n", "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90, fontsize=8)\n", "    plt.yticks(range(len(corr.columns)), corr.columns, fontsize=8)\n", "    plt.tight_layout()\n", "    plt.show()\n", "else:\n", "    print(\"Not enough numeric columns for heatmap.\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 5. Hypothesis Testing"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### H1: Average **Quantity** differs across **Food_Type** (One-way ANOVA)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["groups = [g.dropna().values for _, g in food.groupby('food_type')['quantity']]\n", "if len(groups) >= 2 and all(len(g)>=2 for g in groups):\n", "    F, p = stats.f_oneway(*groups)\n", "    print(f\"ANOVA F={F:.3f}, p-value={p:.6f}\")\n", "    print(\"Decision:\", \"Reject H0\" if p<0.05 else \"Fail to reject H0\")\n", "else:\n", "    print(\"Insufficient group sizes for ANOVA.\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### H2: **Claim success** rate differs by **Meal_Type** (Chi-square)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["def map_success(s):\n", "    s = str(s).strip().lower()\n", "    pos = {'completed','claimed','approved','success','successful','closed'}\n", "    neg = {'pending','rejected','cancelled','canceled','failed','expired'}\n", "    if s in pos: return 1\n", "    if s in neg: return 0\n", "    return np.nan\n", "\n", "claims['success_flag'] = claims['status'].apply(map_success)\n", "cf2 = claims.merge(food[['food_id','meal_type']], on='food_id', how='left')\n", "ct = pd.crosstab(cf2['meal_type'], cf2['success_flag'])\n", "print(ct)\n", "if ct.shape[0] >= 2 and ct.shape[1] >= 2 and (ct.values>0).all():\n", "    chi2, p, dof, exp = stats.chi2_contingency(ct)\n", "    print(f\"Chi-square={chi2:.3f}, dof={dof}, p-value={p:.6f}\")\n", "    print(\"Decision:\", \"Reject H0\" if p<0.05 else \"Fail to reject H0\")\n", "else:\n", "    print(\"Not enough data variation for chi-square test.\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### H3: **Time-to-claim** differs by **Provider_Type** (Mann\u2013Whitney U)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["tmp = claims.merge(food[['food_id','expiry_date','provider_id','provider_type']], on='food_id', how='left')\n", "tmp = tmp.dropna(subset=['timestamp','expiry_date'])\n", "tmp['hours_to_expiry_at_claim'] = (tmp['expiry_date'] - tmp['timestamp']).dt.total_seconds() / 3600.0\n", "\n", "gA = tmp.loc[tmp['provider_type'].fillna('x').str.lower()=='organization', 'hours_to_expiry_at_claim'].dropna()\n", "gB = tmp.loc[tmp['provider_type'].fillna('x').str.lower()!='organization', 'hours_to_expiry_at_claim'].dropna()\n", "\n", "if len(gA)>=10 and len(gB)>=10:\n", "    U, p = stats.mannwhitneyu(gA, gB, alternative='two-sided')\n", "    print(f\"Mann\u2013Whitney U={U:.1f}, p-value={p:.6f}\")\n", "    print(\"Decision:\", \"Reject H0\" if p<0.05 else \"Fail to reject H0\")\n", "else:\n", "    print(\"Insufficient sample size for Mann\u2013Whitney test.\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 6. Feature Engineering & ML Dataset"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["full_ml = food.merge(claims[['food_id','success_flag','timestamp']], on='food_id', how='left')\n", "\n", "# Time features\n", "full_ml['expiry_dayofweek']  = full_ml['expiry_date'].dt.dayofweek\n", "full_ml['expiry_is_weekend'] = full_ml['expiry_dayofweek'].isin([5,6]).astype(int)\n", "\n", "# Clean categories\n", "for col in ['food_type','meal_type','provider_type','location']:\n", "    if col in full_ml.columns:\n", "        full_ml[col] = full_ml[col].astype(str).str.strip().str.lower()\n", "\n", "# Drop rows with no target\n", "ml_df = full_ml.dropna(subset=['success_flag']).copy()\n", "ml_df['success_flag'] = ml_df['success_flag'].astype(int)\n", "\n", "numeric_features = [c for c in ['quantity','expiry_dayofweek','expiry_is_weekend'] if c in ml_df.columns]\n", "categorical_features = [c for c in ['food_type','meal_type','provider_type','location'] if c in ml_df.columns]\n", "\n", "print(\"Numeric features:\", numeric_features)\n", "print(\"Categorical features:\", categorical_features)\n", "print(\"Target counts:\\n\", ml_df['success_flag'].value_counts())\n", "X = ml_df[numeric_features + categorical_features].copy()\n", "y = ml_df['success_flag'].copy()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 6.1 Split + Preprocess + (Optional) SMOTE"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["X_train, X_test, y_train, y_test = train_test_split(\n", "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n", ")\n", "\n", "imbalance_ratio = y_train.mean()\n", "print(f\"Positive class ratio (train): {imbalance_ratio:.3f}\")\n", "\n", "preprocess = ColumnTransformer(\n", "    transformers=[\n", "        (\"num\", StandardScaler(), numeric_features),\n", "        (\"cat\", OneHotEncoder(handle_unknown='ignore', sparse=False), categorical_features)\n", "    ]\n", ")\n", "\n", "USE_SMOTE = (imbalance_ratio < 0.35 or imbalance_ratio > 0.65)\n", "print(\"Using SMOTE:\", USE_SMOTE)\n", "\n", "if USE_SMOTE:\n", "    X_train_arr = preprocess.fit_transform(X_train)\n", "    X_test_arr  = preprocess.transform(X_test)\n", "    sm = SMOTE(random_state=RANDOM_STATE)\n", "    X_train_bal, y_train_bal = sm.fit_resample(X_train_arr, y_train)\n", "else:\n", "    X_train_bal = preprocess.fit_transform(X_train)\n", "    y_train_bal = y_train.copy()\n", "    X_test_arr  = preprocess.transform(X_test)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### 6.2 Evaluation Helpers"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["def evaluate_clf(y_true, y_pred, y_prob=None):\n", "    out = {\n", "        \"accuracy\": accuracy_score(y_true, y_pred),\n", "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n", "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n", "        \"f1\": f1_score(y_true, y_pred, zero_division=0)\n", "    }\n", "    if y_prob is not None:\n", "        try:\n", "            out[\"roc_auc\"] = roc_auc_score(y_true, y_prob)\n", "        except Exception:\n", "            out[\"roc_auc\"] = np.nan\n", "    return out\n", "\n", "def plot_conf_mat(y_true, y_pred, title=\"Confusion Matrix\"):\n", "    cm = confusion_matrix(y_true, y_pred)\n", "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n", "    plt.figure()\n", "    disp.plot()\n", "    plt.title(title)\n", "    plt.tight_layout()\n", "    plt.show()\n", "\n", "def plot_roc_curve(y_true, y_prob, title=\"ROC Curve\"):\n", "    plt.figure()\n", "    RocCurveDisplay.from_predictions(y_true, y_prob)\n", "    plt.title(title)\n", "    plt.tight_layout()\n", "    plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 7. Model 1 \u2014 Logistic Regression"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["logreg = LogisticRegression(max_iter=1000, class_weight='balanced' if not USE_SMOTE else None, random_state=RANDOM_STATE)\n", "\n", "if USE_SMOTE:\n", "    logreg.fit(X_train_bal, y_train_bal)\n", "    y_pred_lr = logreg.predict(X_test_arr)\n", "    try: y_prob_lr = logreg.predict_proba(X_test_arr)[:,1]\n", "    except Exception: y_prob_lr = None\n", "else:\n", "    pipe_lr = Pipeline([(\"prep\", preprocess), (\"clf\", logreg)])\n", "    pipe_lr.fit(X_train, y_train)\n", "    y_pred_lr = pipe_lr.predict(X_test)\n", "    try: y_prob_lr = pipe_lr.predict_proba(X_test)[:,1]\n", "    except Exception: y_prob_lr = None\n", "\n", "metrics_lr = evaluate_clf(y_test, y_pred_lr, y_prob_lr)\n", "print(\"Logistic Regression metrics:\", metrics_lr)\n", "print(\"\\nClassification report (LR):\\n\", classification_report(y_test, y_pred_lr, zero_division=0))\n", "plot_conf_mat(y_test, y_pred_lr, \"LogReg \u2014 Confusion Matrix\")\n", "if y_prob_lr is not None: plot_roc_curve(y_test, y_prob_lr, \"LogReg \u2014 ROC Curve\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 8. Model 2 \u2014 Random Forest (+ GridSearch)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["rf = RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, n_jobs=-1,\n", "                            class_weight='balanced' if not USE_SMOTE else None)\n", "\n", "if USE_SMOTE:\n", "    rf.fit(X_train_bal, y_train_bal)\n", "    y_pred_rf = rf.predict(X_test_arr)\n", "    try: y_prob_rf = rf.predict_proba(X_test_arr)[:,1]\n", "    except Exception: y_prob_rf = None\n", "else:\n", "    pipe_rf = Pipeline([(\"prep\", preprocess), (\"clf\", rf)])\n", "    pipe_rf.fit(X_train, y_train)\n", "    y_pred_rf = pipe_rf.predict(X_test)\n", "    try: y_prob_rf = pipe_rf.predict_proba(X_test)[:,1]\n", "    except Exception: y_prob_rf = None\n", "\n", "metrics_rf = evaluate_clf(y_test, y_pred_rf, y_prob_rf)\n", "print(\"Random Forest metrics:\", metrics_rf)\n", "print(\"\\nClassification report (RF):\\n\", classification_report(y_test, y_pred_rf, zero_division=0))\n", "plot_conf_mat(y_test, y_pred_rf, \"Random Forest \u2014 Confusion Matrix\")\n", "if y_prob_rf is not None: plot_roc_curve(y_test, y_prob_rf, \"Random Forest \u2014 ROC Curve\")\n", "\n", "# Small grid (only when pipeline is usable)\n", "if not USE_SMOTE:\n", "    param_grid = {\n", "        \"clf__n_estimators\": [200, 400],\n", "        \"clf__max_depth\": [None, 10, 20]\n", "    }\n", "    grid_rf = GridSearchCV(\n", "        Pipeline([(\"prep\", preprocess), (\"clf\", RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1))]),\n", "        param_grid, cv=3, scoring='f1', n_jobs=-1, verbose=0\n", "    )\n", "    grid_rf.fit(X_train, y_train)\n", "    print(\"RF GridSearch best params:\", grid_rf.best_params_)\n", "    y_pred_rf_g = grid_rf.predict(X_test)\n", "    try: y_prob_rf_g = grid_rf.predict_proba(X_test)[:,1]\n", "    except Exception: y_prob_rf_g = None\n", "    metrics_rf_grid = evaluate_clf(y_test, y_pred_rf_g, y_prob_rf_g)\n", "    print(\"Random Forest (Grid) metrics:\", metrics_rf_grid)\n", "else:\n", "    print(\"Skipping RF GridSearch on SMOTE branch (pipeline-less).\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 9. Model 3 \u2014 XGBoost (+ GridSearch)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["if XGB_AVAILABLE:\n", "    xgb = XGBClassifier(\n", "        n_estimators=400, max_depth=5, learning_rate=0.1,\n", "        subsample=0.9, colsample_bytree=0.9, random_state=RANDOM_STATE,\n", "        reg_lambda=1.0, n_jobs=-1, eval_metric='logloss'\n", "    )\n", "    if USE_SMOTE:\n", "        xgb.fit(X_train_bal, y_train_bal)\n", "        y_pred_xgb = xgb.predict(X_test_arr)\n", "        try: y_prob_xgb = xgb.predict_proba(X_test_arr)[:,1]\n", "        except Exception: y_prob_xgb = None\n", "    else:\n", "        pipe_xgb = Pipeline([(\"prep\", preprocess), (\"clf\", xgb)])\n", "        pipe_xgb.fit(X_train, y_train)\n", "        y_pred_xgb = pipe_xgb.predict(X_test)\n", "        try: y_prob_xgb = pipe_xgb.predict_proba(X_test)[:,1]\n", "        except Exception: y_prob_xgb = None\n", "\n", "    metrics_xgb = evaluate_clf(y_test, y_pred_xgb, y_prob_xgb)\n", "    print(\"XGBoost metrics:\", metrics_xgb)\n", "    print(\"\\nClassification report (XGB):\\n\", classification_report(y_test, y_pred_xgb, zero_division=0))\n", "    plot_conf_mat(y_test, y_pred_xgb, \"XGBoost \u2014 Confusion Matrix\")\n", "    if y_prob_xgb is not None: plot_roc_curve(y_test, y_prob_xgb, \"XGBoost \u2014 ROC Curve\")\n", "\n", "    if not USE_SMOTE:\n", "        param_grid = {\n", "            \"clf__n_estimators\": [300, 500],\n", "            \"clf__max_depth\": [4, 6],\n", "            \"clf__learning_rate\": [0.05, 0.1]\n", "        }\n", "        grid_xgb = GridSearchCV(\n", "            Pipeline([(\"prep\", preprocess), (\"clf\", XGBClassifier(subsample=0.9, colsample_bytree=0.9,\n", "                                                                  random_state=RANDOM_STATE, eval_metric='logloss'))]),\n", "            param_grid, cv=3, scoring='f1', n_jobs=-1, verbose=0\n", "        )\n", "        grid_xgb.fit(X_train, y_train)\n", "        print(\"XGB GridSearch best params:\", grid_xgb.best_params_)\n", "        y_pred_xgb_g = grid_xgb.predict(X_test)\n", "        try: y_prob_xgb_g = grid_xgb.predict_proba(X_test)[:,1]\n", "        except Exception: y_prob_xgb_g = None\n", "        metrics_xgb_grid = evaluate_clf(y_test, y_pred_xgb_g, y_prob_xgb_g)\n", "        print(\"XGBoost (Grid) metrics:\", metrics_xgb_grid)\n", "    else:\n", "        print(\"Skipping XGB GridSearch on SMOTE branch.\")\n", "else:\n", "    print(\"XGBoost not installed. Install xgboost to enable this model.\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 10. Model Comparison & Selection"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Collect available metric dicts\n", "rows = []\n", "if 'metrics_lr' in locals(): rows.append((\"Logistic Regression\", metrics_lr))\n", "if 'metrics_rf' in locals(): rows.append((\"Random Forest\", metrics_rf))\n", "if 'metrics_xgb' in locals(): rows.append((\"XGBoost\", metrics_xgb))\n", "\n", "# Include grid searched metrics when available\n", "if 'metrics_rf_grid' in locals(): rows.append((\"Random Forest (Grid)\", metrics_rf_grid))\n", "if 'metrics_xgb_grid' in locals(): rows.append((\"XGBoost (Grid)\", metrics_xgb_grid))\n", "\n", "compare_df = pd.DataFrame([dict(model=name, **m) for name, m in rows]).fillna(np.nan)\n", "display(compare_df)\n", "\n", "# Simple metric bar chart (F1)\n", "if not compare_df.empty and 'f1' in compare_df.columns:\n", "    plt.figure()\n", "    plt.bar(compare_df['model'], compare_df['f1'])\n", "    plt.title(\"Model F1 Score Comparison\")\n", "    plt.xticks(rotation=30, ha='right')\n", "    plt.ylabel(\"F1\")\n", "    plt.tight_layout()\n", "    plt.show()\n", "\n", "# Pick best by F1 (fallback to accuracy)\n", "if not compare_df.empty:\n", "    metric_to_use = 'f1' if 'f1' in compare_df.columns else 'accuracy'\n", "    best_row = compare_df.loc[compare_df[metric_to_use].idxmax()]\n", "    BEST_MODEL_NAME = best_row['model']\n", "    print(f\"Selected best model by {metric_to_use}: {BEST_MODEL_NAME}\")\n", "else:\n", "    BEST_MODEL_NAME = None\n", "    print(\"No models trained.\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 11. Save a Deployable Pipeline (.pkl)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import pickle\n", "\n", "# For deployment, retrain a pipeline (without SMOTE) on train data for the chosen algorithm.\n", "def make_pipeline_for(name: str):\n", "    if name.startswith(\"Logistic\"):\n", "        clf = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=RANDOM_STATE)\n", "    elif name.startswith(\"Random Forest\"):\n", "        clf = RandomForestClassifier(n_estimators=400, max_depth=None, random_state=RANDOM_STATE,\n", "                                     n_jobs=-1, class_weight='balanced')\n", "    elif name.startswith(\"XGBoost\"):\n", "        if not XGB_AVAILABLE:\n", "            return None\n", "        clf = XGBClassifier(n_estimators=400, max_depth=5, learning_rate=0.1, subsample=0.9,\n", "                            colsample_bytree=0.9, random_state=RANDOM_STATE, reg_lambda=1.0,\n", "                            n_jobs=-1, eval_metric='logloss')\n", "    else:\n", "        return None\n", "    return Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n", "\n", "deploy_pipe = make_pipeline_for(BEST_MODEL_NAME or \"Random Forest\")\n", "if deploy_pipe is not None:\n", "    deploy_pipe.fit(X_train, y_train)\n", "    y_pred_dep = deploy_pipe.predict(X_test)\n", "    try: y_prob_dep = deploy_pipe.predict_proba(X_test)[:,1]\n", "    except Exception: y_prob_dep = None\n", "    print(\"Deployable pipeline metrics:\", evaluate_clf(y_test, y_pred_dep, y_prob_dep))\n", "    with open(\"best_model_pipeline.pkl\", \"wb\") as f:\n", "        pickle.dump(deploy_pipe, f)\n", "    print(\"Saved: best_model_pipeline.pkl\")\n", "else:\n", "    print(\"Could not create deployable pipeline for:\", BEST_MODEL_NAME)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 12. Feature Importance / Explainability"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["if 'deploy_pipe' in locals() and hasattr(deploy_pipe.named_steps['clf'], 'feature_importances_'):\n", "    # Extract feature names from ColumnTransformer\n", "    ohe = deploy_pipe.named_steps['prep'].named_transformers_['cat']\n", "    num_names = deploy_pipe.named_steps['prep'].transformers_[0][2]\n", "    cat_names = list(ohe.get_feature_names_out(deploy_pipe.named_steps['prep'].transformers_[1][2]))\n", "    feat_names = list(num_names) + cat_names\n", "    importances = deploy_pipe.named_steps['clf'].feature_importances_\n", "\n", "    # Plot top-20\n", "    idx = np.argsort(importances)[::-1][:20]\n", "    plt.figure()\n", "    plt.bar(range(len(idx)), importances[idx])\n", "    plt.xticks(range(len(idx)), [feat_names[i] for i in idx], rotation=90, fontsize=8)\n", "    plt.title(\"Top 20 Feature Importances (Tree-based)\")\n", "    plt.tight_layout()\n", "    plt.show()\n", "elif SHAP_AVAILABLE and 'deploy_pipe' in locals():\n", "    try:\n", "        # Use a small sample for SHAP to keep it fast\n", "        sample_X = X_test.sample(min(400, len(X_test)), random_state=RANDOM_STATE)\n", "        sample_trans = deploy_pipe.named_steps['prep'].transform(sample_X)\n", "        model = deploy_pipe.named_steps['clf']\n", "        explainer = shap.Explainer(model, sample_trans)\n", "        shap_values = explainer(sample_trans)\n", "        # summary_plot uses matplotlib by default\n", "        shap.summary_plot(shap_values, sample_trans, show=True)\n", "    except Exception as e:\n", "        print(\"SHAP explainability skipped:\", e)\n", "else:\n", "    print(\"No tree-based importances and SHAP not available.\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 13. (Optional) Simple Unsupervised Segmentation (KMeans on Providers)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["from sklearn.cluster import KMeans\n", "\n", "prov_feat = providers[['city']].copy()\n", "prov_feat['provider_type'] = providers['provider_type'].astype(str).str.lower()\n", "prov_feat = pd.get_dummies(prov_feat, columns=['city','provider_type'], drop_first=False)\n", "\n", "# Keep it robust: 3 clusters if enough rows, else skip\n", "if len(prov_feat) >= 6:\n", "    km = KMeans(n_clusters=3, n_init=10, random_state=RANDOM_STATE)\n", "    labels = km.fit_predict(prov_feat)\n", "    providers_seg = providers.copy()\n", "    providers_seg['segment'] = labels\n", "    display(providers_seg.head())\n", "    bar_count(pd.Series(labels), \"Provider Segments (KMeans)\")\n", "else:\n", "    print(\"Not enough provider rows for clustering.\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## 14. Conclusion (What to report)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["**Summary:**  \n", "- Completed comprehensive EDA, handled missing values, inspected duplicates/outliers.  \n", "- Validated 3 hypotheses (ANOVA/Chi\u2011square/Mann\u2013Whitney).  \n", "- Engineered features (time\u2011based, categorical cleanup), built multiple models (LR, RF, XGB).  \n", "- Compared metrics (F1/ROC\u2011AUC), selected a best model, and exported a deployable pipeline (`best_model_pipeline.pkl`).  \n", "- Included feature importance/SHAP and a small unsupervised segmentation.\n", "\n", "**Notes for the report:**  \n", "- Emphasize class imbalance handling (SMOTE vs. class weights).  \n", "- Interpret top features from the final model.  \n", "- Show confusion matrix and tie Precision/Recall to business trade\u2011offs (wastage vs. stockouts).  \n", "- State actionable insights from EDA (e.g., cities or meal types with low claim rates)."]}], "metadata": {"colab": {"name": "Food_Wastage_Colab.ipynb"}, "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}